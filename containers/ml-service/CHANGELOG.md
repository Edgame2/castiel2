# Changelog

## [Unreleased]

### Added
- **W10 – Tenant ML config consumption (Layer 3, REQUIREMENTS_GAP_ANALYSIS Gap 4):** Type `TenantMLConfigView` (modelPreferences.preferIndustryModels, minConfidenceThreshold) in `feature-store.types.ts`. `FeatureService.getTenantMLConfig(tenantId)` calls risk-analytics `GET /api/v1/tenant-ml-config` (uses `services.risk_analytics.url`). `ModelSelectionService.selectRiskScoringModel(tenantId, industryId?, features?, tenantConfig?)`: when tenant config has `preferIndustryModels === false`, skips industry model preference. `GET /api/v1/ml/model-selection/risk-scoring` fetches tenant config and passes to selectRiskScoringModel. `PredictionService.predictWinProbability` returns optional `confidenceMet` when tenant config has `minConfidenceThreshold` (probability >= threshold).
- **W9 – Reactivation prediction (Layer 3, FR-3.11):** Types `ReactivationPrediction`, `OptimalReactivationWindow`, `RecommendedReactivationApproach`, `KeySuccessFactor`, `ReactivationRisk` in `feature-store.types.ts`. `ReactivationPredictionService(featureStoreService)`: `predictReactivation(tenantId, opportunityId)` uses dormant features to produce heuristic reactivation probability, confidence, optimal window, recommended approach, key success factors, reactivation risks. `GET /api/v1/ml/reactivation/predict?opportunityId=` returns ReactivationPrediction (404 when opportunity not found).
- **W9 – Dormant opportunity features (Layer 2, REQUIREMENTS_GAP_ANALYSIS FR-1.9):** Type `DormantOpportunityFeatures` in `feature-store.types.ts`. `FeatureService.getOpportunityActivities(tenantId, opportunityId)` (private) fetches related c_email, c_call, c_meeting from shard-manager. `FeatureService.extractDormantOpportunityFeatures(tenantId, opportunityId)` computes inactivity metrics, activity counts (7/30/90 days), engagement scores (stub/derived), timeElapsed/timeToClose, dormancyCategory (recently_dormant | long_dormant | likely_lost), dormancyReason. `FeatureStoreService.extractDormantOpportunityFeatures` delegates. `GET /api/v1/ml/features/reactivation?opportunityId=` returns DormantOpportunityFeatures (404 when opportunity not found).
- **W8 – Sales Methodology features (Layer 2, REQUIREMENTS_GAP_ANALYSIS FR-1.8):** Types `MethodologyFeatures`, `MeddicFeatures` in `feature-store.types.ts`. `FeatureService.getTenantMethodology(tenantId)` calls risk-analytics `GET /api/v1/sales-methodology` (uses existing `services.risk_analytics.url`). `FeatureService.getOpportunityStructuredData(tenantId, opportunityId)` fetches opportunity from shard-manager for methodology extraction. `FeatureStoreService.extractMethodologyFeatures(tenantId, opportunity)` computes stage compliance, days in stage, duration anomaly, methodology field completion, and optional MEDDIC/MEDDPICC features. `GET /api/v1/ml/features/methodology?opportunityId=` returns MethodologyFeatures (404 when opportunity not found).
- **W7 Gap 1 – Risk Catalog integration (Layer 2):** Config `services.risk_catalog.url` (env `RISK_CATALOG_URL`, default http://localhost:3047). Types `RiskCatalogDefinition`, `RiskCatalogTemplateView`, `RiskCatalogFeatures` in `feature-store.types.ts`. `FeatureService.getTenantCatalogView(tenantId, industry?, stage?)` calls risk-catalog `GET /api/v1/risk-catalog/tenant-catalog` (service-to-service auth). `FeatureStoreService.extractRiskCatalogFeatures(tenantId, industry?, stage?)` returns `RiskCatalogFeatures` (FR-1.7). `GET /api/v1/ml/features/risk-catalog?industry=&stage=` for Layer 2 consumption.
- **W6 Layer 8 – Learning Loop (Plan Phase 4):** Types `DriftMetrics`, `ImprovementOpportunity` in `ml.types.ts`. Cosmos containers `drift_metrics` (ml_drift_metrics), `improvement_opportunity` (ml_improvement_opportunity). Events: `ml.training.started`, `ml.training.completed`, `ml.training.failed`, `ml.drift.detected`, `ml.improvement.suggested`. `TrainingService` uses config container name and publishes training events on status change. `EvaluationService`: getDrift(tenantId, modelId, from?, to?, limit?), recordDrift (called by ModelMonitoringService when PSI &gt; threshold). `ContinuousLearningService`: getSuggestions(tenantId, modelId), addSuggestion (publishes ml.improvement.suggested), acknowledge(suggestionId). ModelMonitoringService persists drift to ml_drift_metrics and publishes ml.drift.detected when PSI &gt; threshold. APIs: `GET /api/v1/ml/evaluation/drift/:modelId` (query from, to, limit), `GET /api/v1/ml/learning/suggestions/:modelId` (query acknowledged, limit). OpenAPI paths added.

### Changed
- **Model monitoring – metrics (Plan §8.5.2, §940):** `ml_drift_checks_total`, `ml_drift_detections_total`, **`ml_performance_degraded_total`** (labels `model`, `metric`) in `src/metrics.ts`; incremented when publishing `ml.model.drift.detected` or `ml.model.performance.degraded`. deployment/monitoring/README, model-monitoring runbook §6, ml-service.json panel.
- **Model monitoring – Drift (PSI) (Plan §940, §11.3):** `ModelMonitoringService.runForTenants` now performs PSI-based drift checks when `data_lake.connection_string` is set: reads `/ml_inference_logs` from Data Lake (Parquet; DATA_LAKE_LAYOUT §2.3), baseline window 30–60 days ago, current window last 7 days; computes Population Stability Index on `prediction` per (tenantId, modelId); when PSI > `model_monitoring.psi_threshold` (default 0.2) publishes `ml.model.drift.detected` (metric `psi`, delta). Minimum 30 samples in each window. Dependencies: `@azure/storage-blob`, `parquetjs`; `src/types/parquetjs.d.ts`. Runbook: model-monitoring.md §1, §2, §5.
- **Model monitoring – MAE (Plan §940):** `ModelMonitoringService.runForTenants` now performs MAE-based performance checks: reads `doc.mae` or `doc.metrics.mae`/`MAE` from ml_evaluations; when MAE > `model_monitoring.mae_threshold` (default 0.2) publishes `ml.model.performance.degraded` (metric `mae`). Config: `model_monitoring.mae_threshold`; schema. Runbook model-monitoring §1, §2, §5.
- **Model monitoring (Plan §940):** `ModelMonitoringService.runForTenants` now performs Brier-based performance checks: queries `ml_evaluations` (config `cosmos_db.containers.evaluations`), reads Brier from `doc.brier` or `doc.metrics.brier`/`Brier`; when Brier > `model_monitoring.brier_threshold` (default 0.2) publishes `ml.model.performance.degraded`. `publishMlModelDriftDetected` and `publishMlModelPerformanceDegraded` added to `MLServiceEventPublisher`. Drift (PSI) remains unimplemented (`driftChecked: 0`).
- **train_win_probability.py (Plan §876, TRAINING_SCRIPTS_SPEC §3.2):** Brier and AUC_ROC are now logged to the Azure ML run when the script is executed as an Azure ML Job (`run.log('Brier', ...)`, `run.log('AUC_ROC', ...)` via azureml.core.Run). `conda-win-probability-train.yaml` adds `azureml-core` for run context.
- **train_risk_scoring.py (Plan §874):** RMSE, MAE, and R2 are now logged to the Azure ML run when the script is executed as an Azure ML Job (`run.log('RMSE', ...)`, `run.log('MAE', ...)`, `run.log('R2', ...)` via azureml.core.Run). `conda-risk-scoring-train.yaml` adds `scikit-learn` (for metrics) and `azureml-core` for run context.
- **train_lstm_trajectory.py (Plan §875):** loss, val_loss, mae, and val_mae (final epoch) are now logged to the Azure ML run when the script is executed as an Azure ML Job (`run.log('loss', ...)`, `run.log('val_loss', ...)`, `run.log('mae', ...)`, `run.log('val_mae', ...)` via azureml.core.Run). `conda-lstm-train.yaml` adds `azureml-core` for run context.
- **train_prophet_forecast.py (Plan §877):** MAPE, RMSE, and MAE (in-sample) are now logged to the Azure ML run when the script is executed as an Azure ML Job (`run.log('MAPE', ...)`, `run.log('RMSE', ...)`, `run.log('MAE', ...)` via azureml.core.Run). `conda-prophet-train.yaml` adds `azureml-core` for run context.
- **train_anomaly_isolation_forest.py (Plan Phase 2, TRAINING_SCRIPTS_SPEC §3.4):** F1 (anomaly class) is now logged to the Azure ML run when the script is executed as an Azure ML Job and the input has an `is_anomaly` column (`run.log('F1', ...)` via azureml.core.Run). `conda-anomaly-train.yaml` adds `azureml-core` for run context.

### Added
- **Layer 3 prediction cache (W4):** Optional Redis prediction cache in `PredictionService` for win_probability, risk_scoring, and anomaly. Cache key `prediction:{tenantId}:{opportunityId}:{modelType}`; TTL from `cache.redis.ttl_seconds`. `getCachedPrediction`/`setCachedPrediction`/`invalidatePredictionCache(tenantId, opportunityId)`. `POST /api/v1/ml/predictions/cache/invalidate` (body: opportunityId) for invalidation on opportunity.updated.
- **Layer 3 events (W4):** `publishMlPredictionRequested(tenantId, { requestId, opportunityId?, modelId })`, `publishMlPredictionFailed(tenantId, { requestId?, opportunityId?, modelId, error, durationMs })`, `publishMlModelDeployed(tenantId, { modelId, version })`, `publishMlModelHealthDegraded(tenantId, { modelId, metric, value, threshold, message? })`. ml.prediction.completed now accepts optional `requestId`. Requested emitted at start of predictWinProbability, predictRiskScore, predictAnomaly (after cache miss); failed emitted on predictAnomaly throw and on risk-trajectory route catch; ml.model.deployed emitted after POST /api/v1/ml/models/:id/deploy success.
- **Layer 3 circuit breaker and retry (W4):** `AzureMLClient` caches `ServiceClient` per endpoint URL so circuit breaker state is shared across calls. Each client uses `retries: 3` (exponential backoff in ServiceClient), `circuitBreaker: { enabled: true, threshold: 5, timeout: 30000 }`. Inference timeout 2s default (DEFAULT_INFERENCE_TIMEOUT_MS) for predict, predictAnomaly, predictLstmTrajectory; FORECAST_TIMEOUT_MS 20s for predictRevenueForecast.
- **Layer 3 model health API (W4):** `GET /api/v1/ml/models/health` (auth + tenant). Returns `{ endpoints: { [modelId]: { status: 'ok'|'unreachable', latencyMs } }, overall: 'ok'|'degraded'|'not_configured', timestamp }` by probing each configured Azure ML endpoint (2s timeout).
- **Layer 2 Feature Engineering (W3, COMPREHENSIVE_LAYER_REQUIREMENTS_SUMMARY, LAYER_2_FEATURE_ENGINEERING_REQUIREMENTS):** `FeatureStoreService` (extract via FeatureService, optional Redis cache, persist snapshot, export), `FeatureVersionManager` (pin/resolve/deprecate), `FeatureQualityMonitor` (missing rate, outliers, drift). Cosmos containers: `feature_snapshots` (ml_feature_snapshots), `feature_metadata` (ml_feature_metadata). Types: `FeatureSnapshot`, `FeatureMetadata`, `FeatureStatistic`, `FeatureSchemaDefinition` in `src/types/feature-store.types.ts`. APIs: `GET /api/v1/ml/features/opportunity/:opportunityId`, `POST /api/v1/ml/features/batch`, `GET /api/v1/ml/features/schema`, `GET /api/v1/ml/features/statistics`, `POST /api/v1/ml/features/export`, `GET /api/v1/ml/features/snapshots/:snapshotId`, `GET /api/v1/ml/features/versions/resolve`, `GET /api/v1/ml/features/versions`, `POST /api/v1/ml/features/versions` (upsert), `POST /api/v1/ml/features/versions/pin`, `POST /api/v1/ml/features/versions/deprecate`, `GET /api/v1/ml/features/quality`, `POST /api/v1/ml/features/cache/invalidate`. RabbitMQ events: `publishFeatureExtractionRequested`, `publishFeatureExtractionCompleted`, `publishFeatureCacheInvalidated`, `publishFeatureQualityAlert` (feature.extraction.requested/completed, feature.cache.invalidated, feature.quality.alert). Config: `cosmos_db.containers.feature_snapshots`, `cosmos_db.containers.feature_metadata`; optional `cache.redis` for feature cache.
- **Win-probability trend (Gaps 6, 9, Plan §4.2):** `cosmos_db.containers.win_probability` (ml_win_probability_predictions). `feature_flags.persist_win_probability`; optional upsert in `predictWinProbability` after successful prediction. `PredictionService.getProbabilityTrend(tenantId, opportunityId, from?, to?)`. `GET /api/v1/ml/win-probability/:opportunityId/trend` (query from, to). Returns `{ points: [] }` when container not configured or no data. OpenAPI path added.
- **Config `data_lake` (Plan §9.3, §11.3, model-monitoring runbook §5):** `data_lake.connection_string`, `data_lake.container`, `data_lake.ml_inference_logs_prefix` (default `/ml_inference_logs`). For model-monitoring PSI when implemented: read inference logs from same path as logging DataLakeCollector. Env: `DATA_LAKE_CONNECTION_STRING`, `DATA_LAKE_CONTAINER`, `DATA_LAKE_ML_INFERENCE_LOGS_PREFIX`. When `connection_string` empty, PSI is skipped.
- **AzureMLClient.predictRevenueForecast(modelId, history, periods)** (Plan §877): Prophet scoring; request `{ history, periods }`, response `{ p10, p50, p90 }` (scalars from first period). Endpoint key `revenue_forecasting`.
- **PredictionService.predictRevenueForecastPeriod(history, periods?)** (Plan §877): Calls `predictRevenueForecast('revenue_forecasting', history, periods ?? 1)` when endpoint configured; throws when not (route returns 503).
- **POST /api/v1/ml/forecast/period** (Plan §877): Body `{ history: [[date, value], ...], periods? }`; returns `{ p10, p50, p90, modelId: 'revenue-forecasting-model' }`. 503 when `revenue_forecasting` endpoint not configured. Same auth as risk-trajectory/anomaly. Consumed by forecasting getMLForecast.
- **train_risk_scoring.py (Plan §5.6, §762, §874; BI_SALES_RISK_TRAINING_SCRIPTS_SPEC §3.1):** `scripts/train_risk_scoring.py` for risk-scoring-global / risk-scoring-{industry}. Args: --input-path, --model-name, --industry-id, --run-name, --tenant-id, --deploy, --param-n_estimators, --param-max_depth. XGBRegressor; REQUIRED columns + target_risk; save model.json. **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.json')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (name=model_name-ep, auth_mode=key), ManagedOnlineDeployment (blue) with model=registered, Environment(conda_file=conda-risk-scoring.yaml, image=openmpi4.1.0-ubuntu20.04), CodeConfiguration(scripts dir, score_risk_scoring.py), instance_type=env DEPLOY_INSTANCE_TYPE (default Standard_DS2_v2), instance_count=env DEPLOY_INSTANCE_COUNT (default 1); traffic 100% to blue. `scripts/conda-risk-scoring.yaml` (python, numpy, xgboost). Deploy failure: log and re-raise. `scripts/README.md`. Calibrate N/A for regressor.
- **score_risk_scoring.py (Plan §4.1, §874):** `scripts/score_risk_scoring.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of risk-scoring. init(): load model.json (XGBoost Booster) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"feature": v, ...}]}`, return `{"riskScore": float}`. FEATURE_ORDER matches train_risk_scoring (minus target_risk). Use as code_configuration.scoring_script when deploying. Deps: xgboost, numpy.
- **train_lstm_trajectory.py (Plan §762, §875; TRAINING_SCRIPTS_SPEC §3.3):** `scripts/train_lstm_trajectory.py` for risk-trajectory-lstm. Args: --input-path, --model-name, --sequence-length, --run-name, --tenant-id, --deploy, --param-units, --param-epochs. Keras LSTM; sequences per opportunityId from Parquet (risk_score, activity_count_30d, days_since_last_activity); targets target_risk_30/60/90 or target_risk; saves `risk_trajectory_lstm/saved_model`. **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='risk_trajectory_lstm')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_lstm_trajectory.py, Environment(conda_file=conda-lstm.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-lstm.yaml`, `scripts/score_lstm_trajectory.py`. `tensorflow` in `scripts/requirements-training.txt`.
- **score_lstm_trajectory.py (Plan §4.1, §875):** `scripts/score_lstm_trajectory.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of risk-trajectory-lstm. init(): load TF SavedModel from AZUREML_MODEL_DIR (saved_model or risk_trajectory_lstm/saved_model). run(raw_data): parse `{"sequence": [[r,a,d],...]}` or `{"input": [{"sequence":...}]}`, pad/truncate to SEQUENCE_LENGTH (env, default 30), return `{"risk_30", "risk_60", "risk_90", "confidence"}`. Deps: tensorflow, numpy.
- **train_win_probability.py (Plan §763, §876; TRAINING_SCRIPTS_SPEC §3.2):** `scripts/train_win_probability.py` for win-probability-model. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --param-n_estimators, --param-max_depth, --param-method (isotonic|sigmoid), --param-cv. Parquet: same feature set as risk-scoring + target_win; filter is_closed==1. XGBClassifier + CalibratedClassifierCV; Brier, AUC-ROC; saves model.joblib (model + feature_columns). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_win_probability.py, Environment(conda_file=conda-win-probability.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-win-probability.yaml`, `scripts/score_win_probability.py`. `scikit-learn` in `scripts/requirements-training.txt`.
- **score_win_probability.py (Plan §4.1, §876):** `scripts/score_win_probability.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of win-probability. init(): load model.joblib (CalibratedClassifierCV + feature_columns) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"feature": v, ...}]}`, return `{"winProbability": float, "confidence": float}`. Feature order from artifact["feature_columns"]. Deps: scikit-learn, numpy, joblib (via sklearn).
- **train_prophet_forecast.py (Plan §877, TRAINING_SCRIPTS_SPEC §3.5):** `scripts/train_prophet_forecast.py` for revenue-forecasting-model. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --date-col, --value-col, --param-interval_width, --param-periods, --param-yearly_seasonality, --param-weekly_seasonality. Parquet: (date, revenue) or (ds, y) or (date, pipeline_value); aggregate by date; Prophet for P10/P50/P90. Saves model.joblib (model + interval_width, periods_default). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_prophet_forecast.py, Environment(conda_file=conda-prophet.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-prophet.yaml`, `scripts/score_prophet_forecast.py`. `prophet` in `scripts/requirements-training.txt`.
- **score_prophet_forecast.py (Plan §4.1, §877):** `scripts/score_prophet_forecast.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of revenue-forecasting. init(): load model.joblib (Prophet + interval_width, periods_default) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"history": [[ds,y],...] or [{"ds","y"}], "periods": int (optional)}` or `{"input": [{"history": [...], "periods":...}]}`; extend from max(history ds) or model.make_future_dataframe(periods); return `{"p10", "p50", "p90"}`. Deps: prophet, pandas, numpy, joblib.
- **train_anomaly_isolation_forest.py (Plan Phase 2, TRAINING_SCRIPTS_SPEC §3.4):** `scripts/train_anomaly_isolation_forest.py` for anomaly-detection-isolation-forest. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --param-contamination, --param-n_estimators. Parquet: feature columns only; optional is_anomaly for validation (F1). sklearn.ensemble.IsolationForest. Saves model.joblib (model + feature_columns). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_anomaly_isolation_forest.py, Environment(conda_file=conda-anomaly.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-anomaly.yaml`, `scripts/score_anomaly_isolation_forest.py`. Uses scikit-learn.
- **score_anomaly_isolation_forest.py (Plan Phase 2):** `scripts/score_anomaly_isolation_forest.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of anomaly-detection-isolation-forest. init(): load model.joblib (IsolationForest + feature_columns) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"f1": v1, ...}]}`, return `{"isAnomaly": int (-1|1), "anomalyScore": float}`. Deps: scikit-learn, numpy.
- **generate_synthetic_opportunities.py (Plan §5.6, TRAINING_SCRIPTS_SPEC §3.6):** `scripts/generate_synthetic_opportunities.py` for risk-scoring / win-probability when real data < 3k/5k. Domain rules: amount log-normal, probability beta, stage categorical, target_risk = f(probability, days_since_activity). Args: --output-path, --n-samples, --tenant-id, --seed, --pct-closed. Output: Parquet to ml_training/synthetic/risk_scoring/ or --output-path. Uses numpy, pandas, pyarrow. No new deps.
- **prepare_training_data.py (DATA_LAKE_LAYOUT §2.4, TRAINING_SCRIPTS_SPEC §2.1):** `scripts/prepare_training_data.py` joins /risk_evaluations + /ml_outcomes and writes /ml_training/{model_id}/ Parquet. Args: --risk-evaluations-path, --ml-outcomes-path, --output-path, --model-id (outcome_joined | risk_scoring | win_probability), --tenant-id, --partition-date. outcome_joined = base + target_win, target_risk, is_closed for downstream enrichment; risk_scoring | win_probability add placeholder feature columns so train_risk_scoring / train_win_probability can consume (for production, enrich with shard-manager or buildFeatureVector first). Deps: pandas, pyarrow; adlfs for abfs://. `scripts/conda-prepare-train.yaml` (pandas, pyarrow, adlfs). `scripts/azml-job-prepare-training.yaml` – Azure ML v2 command job: inputs risk_evaluations, ml_outcomes (uri_folder), model_id, tenant_id, partition_date; outputs training_prep (uri_folder). `scripts/azml-pipeline-prepare-then-risk-scoring.yaml` – Azure ML v2 pipeline: prepare_training_data → train_risk_scoring; pipeline inputs risk_evaluations, ml_outcomes, model_name, industry_id, deploy_flag. `scripts/azml-pipeline-prepare-then-win-probability.yaml` – Pipeline: prepare (model_id=win_probability) → train_win_probability; inputs risk_evaluations, ml_outcomes, model_name, deploy_flag. `scripts/README.md`, DATA_LAKE_LAYOUT §2.4, ml-training-jobs runbook.
- **ModelSelectionService (Plan §5.4, §874):** `selectRiskScoringModel(tenantId, industryId?, features?)` — global vs industry; stub: industry when industryId and `risk_scoring_industry` endpoint; else global. `selectWinProbabilityModel(tenantId)` — stub: `win-probability-model` or `win_probability` when configured. `GET /api/v1/ml/model-selection/risk-scoring?industryId=`, `GET /api/v1/ml/model-selection/win-probability`. OpenAPI and auth.
- **Health (Plan §11.7):** `/health` includes `azureMl: { status, endpoints }` (Azure ML endpoints reachability: ok, degraded, not_configured). Custom /health and /ready replace setupHealthCheck.
- **Observability (Plan §8.5, FIRST_STEPS §1):** `@azure/monitor-opentelemetry` in `src/instrumentation.ts` (init before other imports; env `APPLICATIONINSIGHTS_CONNECTION_STRING`, `APPLICATIONINSIGHTS_DISABLE`). `GET /metrics` (prom-client): `http_requests_total`, `http_request_duration_seconds`, `ml_predictions_total` (label `model`), **`ml_prediction_duration_seconds`** (label `model`, Plan §8.5.2, deployment/monitoring/README). Config: `application_insights` (connection_string, disable), `metrics` (path, require_auth, bearer_token); schema. Optional Bearer on /metrics when `metrics.require_auth`. `ml_predictions_total.inc({ model })` and `mlPredictionDurationSeconds.startTimer()` in risk-scoring, win-probability (predict + explain), forecast, generic /models/:id/predict.
- **AzureMLClient** (BI_SALES_RISK Plan §5.4): REST client for Azure ML Managed Endpoints; `predict(modelId, features)`; config `azure_ml.endpoints` (modelId → scoring URL), `azure_ml.api_key`. Env: `AZURE_ML_WIN_PROBABILITY_URL`, `AZURE_ML_RISK_SCORING_URL`; Plan §8.2 aliases: `AZURE_ML_ENDPOINT_WIN_PROB`, `AZURE_ML_ENDPOINT_RISK_GLOBAL`. Degraded: heuristic when Azure ML unavailable (Plan §5.7).
- **PredictionService.predictWinProbability(tenantId, opportunityId)** (Plan §5.4, §5.7): buildVector('win-probability') → Azure ML `win-probability-model` when configured; on failure use heuristic (vector.probability or 0.5).
- **PredictionService.predictRiskScore** extended: when `body.features` missing → `buildVector('risk-scoring')`; when `azure_ml.endpoints['risk-scoring-model']` set → try Azure ML first, then Cosmos model / heuristic.
- **POST /api/v1/ml/win-probability/predict** (Plan §5.4): body `{ opportunityId }`; returns `{ probability }`; uses Azure ML or heuristic.
- **POST /api/v1/ml/win-probability/explain** (Plan §905, §11.2): body `{ opportunityId }`; returns `{ topDrivers: [{ feature, contribution, direction }] }`. PredictionService.getWinProbabilityExplain: top features by |value| from buildVector('win-probability'); Phase 2: tree importance or SHAP.
- **POST /api/v1/ml/anomaly/predict (Plan §5.5):** body `{ opportunityId }`; returns `{ isAnomaly, anomalyScore }`. PredictionService.predictAnomaly: buildVector('anomaly') → AzureMLClient.predictAnomaly('anomaly', features). Request `{ input: [features] }`; response isAnomaly (-1=anomaly, 1=normal), anomalyScore (higher=more anomalous). Requires azure_ml.endpoints.anomaly. ml_predictions_total, ml_prediction_duration_seconds (model 'anomaly'); ml.prediction.completed from predictAnomaly.
- **POST /api/v1/ml/risk-trajectory/predict (Plan §5.5, §875):** body `{ sequence: number[][] }` (from risk_snapshots [riskScore, 0, 0] per row, pad to 30); returns `{ risk_30, risk_60, risk_90, confidence }`. AzureMLClient.predictLstmTrajectory('risk_trajectory_lstm', sequence); PredictionService.predictLstmTrajectory(sequence). Requires azure_ml.endpoints.risk_trajectory_lstm. 503 when endpoint not configured. ml_predictions_total, ml_prediction_duration_seconds (model 'risk_trajectory_lstm'). OpenAPI /ml/risk-trajectory/predict.
- **Azure ML Job for risk-scoring (Plan §874, §5.6):** `scripts/azml-job-risk-scoring.yaml` — Azure ML v2 command job to run `train_risk_scoring.py`. Inputs: training_data (uri_folder; set path to Data Lake or azureml:dataset:1), model_name, industry_id, deploy_flag (set to `--deploy` to deploy after register). `scripts/conda-risk-scoring-train.yaml` — conda env for the job (pandas, pyarrow, xgboost, azure-ai-ml, azure-identity). `scripts/README.md`: how to submit, synthetic data when real data < 3k via `generate_synthetic_opportunities.py`.
- **Azure ML Job for risk-trajectory-lstm (Plan §875, §5.6):** `scripts/azml-job-lstm-trajectory.yaml` — Azure ML v2 command job to run `train_lstm_trajectory.py`. Inputs: training_data (uri_folder; path to risk_snapshots Parquet or azureml:dataset), model_name, sequence_length (default 30), deploy_flag (set to `--deploy` to deploy). `scripts/conda-lstm-train.yaml` — conda env for the job (pandas, pyarrow, tensorflow, azure-ai-ml, azure-identity). `scripts/README.md`: input schema (opportunityId, snapshotDate, risk_score, activity_count_30d, days_since_last_activity, target_risk_30/60/90 or target_risk); SEQUENCE_LENGTH for scoring.
- **Azure ML Job for win-probability (Plan §876, §5.6):** `scripts/azml-job-win-probability.yaml` — Azure ML v2 command job to run `train_win_probability.py`. Inputs: training_data (uri_folder; path to Parquet or azureml:dataset), model_name (default win-probability-model), deploy_flag (set to `--deploy` to deploy). `scripts/conda-win-probability-train.yaml` — conda env for the job (pandas, pyarrow, scikit-learn, xgboost, azure-ai-ml, azure-identity). Input schema: amount, probability, days_to_close, stage_encoded, industry_encoded, days_since_last_activity, activity_count_30d, stakeholder_count, target_win; is_closed; source: /ml_training/win_probability/, risk_evaluations+outcomes, or generate_synthetic_opportunities --pct-closed.
- **Azure ML Job for revenue-forecasting (Plan §877, §5.6):** `scripts/azml-job-prophet.yaml` — Azure ML v2 command job to run `train_prophet_forecast.py`. Inputs: training_data (uri_folder; path to Parquet or azureml:dataset), model_name (default revenue-forecasting-model), deploy_flag (set to `--deploy` to deploy). `scripts/conda-prophet-train.yaml` — conda env for the job (pandas, pyarrow, prophet, joblib, azure-ai-ml, azure-identity). Input: (date, revenue) or (ds, y) or (date, pipeline_value) or (date, target_revenue); source: /ml_training/revenue_forecasting/, historical closed-won or pipeline by date.
- **Azure ML Job for anomaly (Plan Phase 2, TRAINING_SCRIPTS_SPEC §3.4):** `scripts/azml-job-anomaly.yaml` — Azure ML v2 command job to run `train_anomaly_isolation_forest.py`. Inputs: training_data (uri_folder), model_name (default anomaly-detection-isolation-forest), param_contamination (default 0.1), param_n_estimators (default 100), deploy_flag (set to `--deploy` to deploy). `scripts/conda-anomaly-train.yaml` — conda env for the job (pandas, pyarrow, scikit-learn, joblib, azure-ai-ml, azure-identity). Input: feature columns only; optional is_anomaly; source: /ml_training/anomaly/ or /ml_inference_logs/. `scripts/README.md`.
- **FeatureService.buildVectorForOpportunity(tenantId, opportunityId, purpose)** (BI_SALES_RISK_FEATURE_PIPELINE_SPEC, FIRST_STEPS §6): builds `Record<string, number>` from shard-manager (opportunity, account, /related for c_email, c_call, c_meeting, c_contact) and risk-analytics (risk-snapshots). Config: `services.shard_manager.url`, `services.risk_analytics.url`; optional `feature_pipeline.stage_labels`, `feature_pipeline.industry_labels`.
- **FeatureService:** fallback to risk-analytics `GET /api/v1/risk/opportunities/:id/latest-evaluation` when risk-snapshots is empty (FEATURE_PIPELINE_SPEC §2.2).
- **POST /api/v1/ml/features/build** (FIRST_STEPS §6): body `{ opportunityId, purpose }` (purpose: risk-scoring | win-probability | lstm | anomaly | forecasting); returns `{ features: Record<string, number> }`; 404 when opportunity not found.
- **README:** Document `POST /api/v1/ml/features/build`, `services.shard_manager.url`, `services.risk_analytics.url`, and `feature_pipeline.stage_labels` / `industry_labels` (FEATURE_PIPELINE_SPEC §6, FIRST_STEPS §6).
- **ml.prediction.completed (Plan §7.1, §3.5):** ml-service publishes `ml.prediction.completed` from `predictWinProbability`, `predictRiskScore`, and `predictForecast` with `{ modelId, opportunityId?, inferenceMs }` for logging/audit (MLAuditConsumer) and Usage Tracking (analytics-service). Event publisher init/close in server startup and graceful shutdown.
- **Config (Plan §895, §8.2):** `feature_flags` (use_win_probability_ml, use_risk_scoring_ml, use_revenue_forecasting_ml; env USE_*). `azure_ml.endpoints` Plan §8.2: risk_scoring_global, risk_scoring_industry, risk_trajectory_lstm, win_probability, revenue_forecasting, clustering, propagation, anomaly, mitigation_ranking; backward compat: win-probability-model, risk-scoring-model. Env: AZURE_ML_ENDPOINT_RISK_GLOBAL, AZURE_ML_ENDPOINT_WIN_PROB, etc.
- **Config (Plan §867, §8.2):** `azure_ml.workspace_name`, `azure_ml.resource_group`, `azure_ml.subscription_id` for Azure ML Workspace (SDK, batch, deployment). Env: `AZURE_ML_WORKSPACE_NAME`, `AZURE_ML_RESOURCE_GROUP`, `AZURE_ML_SUBSCRIPTION_ID`; default `resource_group`: `castiel-ml-prod-rg` (Plan §5.1).
- **Model card (Plan §11.9, §946):** `MLModelService.getModelCard(modelId, tenantId)` returns `{ modelId, name, type, version, purpose, input, output, limitations }`. Purpose from description or "Model for {type}"; input = features; output by ModelType; limitations from `ml_models.limitations` or `[]`. `GET /api/v1/ml/models/:id/card`. Optional `limitations` on `MLModel` and `UpdateMLModelInput` (writable via PUT /ml/models/:id). Segment fairness in model-monitoring: §946 (alert if delta > threshold) deferred to model-monitoring job.
- **Model monitoring (Plan §940, §9.3):** `ModelMonitoringService.runForTenants(tenantIds)`. Stub returns `{ driftChecked: 0, performanceChecked: 0 }`. Full: log feature vector at inference (Data Lake or ml_inference_logs); drift (PSI), performance (Brier, MAE); publish `ml.model.drift.detected` / `ml.model.performance.degraded`; runbook. `POST /api/v1/ml/model-monitoring/run` body `{ tenantIds?: string[] }` — internal, called by risk-analytics BatchJobWorker. No auth (internal); service-to-service JWT TBD.

## [1.2.0] - 2026-01-23

### Fixed
- **PredictionService**: `error: any` → `error: unknown` in predict, recordOutcome, getById, list; `error.code` via `(error as { code?: number }).code`; throw/console.warn messages use type guards.
- **FeatureService**: `error: any` → `error: unknown` in getAdaptiveFeatureWeights, create, getById, update, list; `error.code` via type assertion; throw messages use type guards.

## [1.1.0] - 2026-01-23

### Added
- `POST /api/v1/ml/risk-scoring/predict` (MISSING_FEATURES 4.2): risk-scoring endpoint used by risk-analytics; uses deployed model when available, falls back to feature-based heuristic when model is missing or not deployed
- `PredictionService.predictRiskScore()` for risk-scoring flow
- `POST /api/v1/ml/forecast/predict` (MISSING_FEATURES 5.1): revenue forecast with P10/P50/P90 (uncertainty), best/base/worst scenarios; uses deployed model when available, else feature-based heuristic; consumed by forecasting service
- `PredictionService.predictForecast()` for forecast flow

## [1.0.0] - 2025-01-22

### Added
- Initial module extraction from monolithic API
- Feature store service
- Model management service
- Training service
- Evaluation service
- Calibration service
- Synthetic data service
- Risk scoring predictions
- Revenue forecasting
- ML-based recommendations
- Event publishing
- Cosmos DB NoSQL integration

