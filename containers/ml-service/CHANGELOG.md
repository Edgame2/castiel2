# Changelog

## [Unreleased]

### Added
- **AzureMLClient.predictRevenueForecast(modelId, history, periods)** (Plan §877): Prophet scoring; request `{ history, periods }`, response `{ p10, p50, p90 }` (scalars from first period). Endpoint key `revenue_forecasting`.
- **PredictionService.predictRevenueForecastPeriod(history, periods?)** (Plan §877): Calls `predictRevenueForecast('revenue_forecasting', history, periods ?? 1)` when endpoint configured; throws when not (route returns 503).
- **POST /api/v1/ml/forecast/period** (Plan §877): Body `{ history: [[date, value], ...], periods? }`; returns `{ p10, p50, p90, modelId: 'revenue-forecasting-model' }`. 503 when `revenue_forecasting` endpoint not configured. Same auth as risk-trajectory/anomaly. Consumed by forecasting getMLForecast.
- **train_risk_scoring.py (Plan §5.6, §762, §874; BI_SALES_RISK_TRAINING_SCRIPTS_SPEC §3.1):** `scripts/train_risk_scoring.py` for risk-scoring-global / risk-scoring-{industry}. Args: --input-path, --model-name, --industry-id, --run-name, --tenant-id, --deploy, --param-n_estimators, --param-max_depth. XGBRegressor; REQUIRED columns + target_risk; save model.json. **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.json')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (name=model_name-ep, auth_mode=key), ManagedOnlineDeployment (blue) with model=registered, Environment(conda_file=conda-risk-scoring.yaml, image=openmpi4.1.0-ubuntu20.04), CodeConfiguration(scripts dir, score_risk_scoring.py), instance_type=env DEPLOY_INSTANCE_TYPE (default Standard_DS2_v2), instance_count=env DEPLOY_INSTANCE_COUNT (default 1); traffic 100% to blue. `scripts/conda-risk-scoring.yaml` (python, numpy, xgboost). Deploy failure: log and re-raise. `scripts/README.md`. Calibrate N/A for regressor.
- **score_risk_scoring.py (Plan §4.1, §874):** `scripts/score_risk_scoring.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of risk-scoring. init(): load model.json (XGBoost Booster) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"feature": v, ...}]}`, return `{"riskScore": float}`. FEATURE_ORDER matches train_risk_scoring (minus target_risk). Use as code_configuration.scoring_script when deploying. Deps: xgboost, numpy.
- **train_lstm_trajectory.py (Plan §762, §875; TRAINING_SCRIPTS_SPEC §3.3):** `scripts/train_lstm_trajectory.py` for risk-trajectory-lstm. Args: --input-path, --model-name, --sequence-length, --run-name, --tenant-id, --deploy, --param-units, --param-epochs. Keras LSTM; sequences per opportunityId from Parquet (risk_score, activity_count_30d, days_since_last_activity); targets target_risk_30/60/90 or target_risk; saves `risk_trajectory_lstm/saved_model`. **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='risk_trajectory_lstm')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_lstm_trajectory.py, Environment(conda_file=conda-lstm.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-lstm.yaml`, `scripts/score_lstm_trajectory.py`. `tensorflow` in `scripts/requirements-training.txt`.
- **score_lstm_trajectory.py (Plan §4.1, §875):** `scripts/score_lstm_trajectory.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of risk-trajectory-lstm. init(): load TF SavedModel from AZUREML_MODEL_DIR (saved_model or risk_trajectory_lstm/saved_model). run(raw_data): parse `{"sequence": [[r,a,d],...]}` or `{"input": [{"sequence":...}]}`, pad/truncate to SEQUENCE_LENGTH (env, default 30), return `{"risk_30", "risk_60", "risk_90", "confidence"}`. Deps: tensorflow, numpy.
- **train_win_probability.py (Plan §763, §876; TRAINING_SCRIPTS_SPEC §3.2):** `scripts/train_win_probability.py` for win-probability-model. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --param-n_estimators, --param-max_depth, --param-method (isotonic|sigmoid), --param-cv. Parquet: same feature set as risk-scoring + target_win; filter is_closed==1. XGBClassifier + CalibratedClassifierCV; Brier, AUC-ROC; saves model.joblib (model + feature_columns). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_win_probability.py, Environment(conda_file=conda-win-probability.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-win-probability.yaml`, `scripts/score_win_probability.py`. `scikit-learn` in `scripts/requirements-training.txt`.
- **score_win_probability.py (Plan §4.1, §876):** `scripts/score_win_probability.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of win-probability. init(): load model.joblib (CalibratedClassifierCV + feature_columns) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"feature": v, ...}]}`, return `{"winProbability": float, "confidence": float}`. Feature order from artifact["feature_columns"]. Deps: scikit-learn, numpy, joblib (via sklearn).
- **train_prophet_forecast.py (Plan §877, TRAINING_SCRIPTS_SPEC §3.5):** `scripts/train_prophet_forecast.py` for revenue-forecasting-model. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --date-col, --value-col, --param-interval_width, --param-periods, --param-yearly_seasonality, --param-weekly_seasonality. Parquet: (date, revenue) or (ds, y) or (date, pipeline_value); aggregate by date; Prophet for P10/P50/P90. Saves model.joblib (model + interval_width, periods_default). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_prophet_forecast.py, Environment(conda_file=conda-prophet.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-prophet.yaml`, `scripts/score_prophet_forecast.py`. `prophet` in `scripts/requirements-training.txt`.
- **score_prophet_forecast.py (Plan §4.1, §877):** `scripts/score_prophet_forecast.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of revenue-forecasting. init(): load model.joblib (Prophet + interval_width, periods_default) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"history": [[ds,y],...] or [{"ds","y"}], "periods": int (optional)}` or `{"input": [{"history": [...], "periods":...}]}`; extend from max(history ds) or model.make_future_dataframe(periods); return `{"p10", "p50", "p90"}`. Deps: prophet, pandas, numpy, joblib.
- **train_anomaly_isolation_forest.py (Plan Phase 2, TRAINING_SCRIPTS_SPEC §3.4):** `scripts/train_anomaly_isolation_forest.py` for anomaly-detection-isolation-forest. Args: --input-path, --model-name, --run-name, --tenant-id, --deploy, --param-contamination, --param-n_estimators. Parquet: feature columns only; optional is_anomaly for validation (F1). sklearn.ensemble.IsolationForest. Saves model.joblib (model + feature_columns). **Azure ML register:** when AZURE_ML_* set, ml_client.models.create_or_update(Model(name, path='model.joblib')); ImportError/Exception fallback. **Azure ML deploy (--deploy):** when register succeeds and --deploy, creates ManagedOnlineEndpoint (model_name-ep), ManagedOnlineDeployment (blue) with score_anomaly_isolation_forest.py, Environment(conda_file=conda-anomaly.yaml), CodeConfiguration; DEPLOY_INSTANCE_TYPE/COUNT; traffic 100% to blue. Deploy failure: log and re-raise. `scripts/conda-anomaly.yaml`, `scripts/score_anomaly_isolation_forest.py`. Uses scikit-learn.
- **score_anomaly_isolation_forest.py (Plan Phase 2):** `scripts/score_anomaly_isolation_forest.py` — scoring entrypoint for Azure ML ManagedOnlineDeployment of anomaly-detection-isolation-forest. init(): load model.joblib (IsolationForest + feature_columns) from AZUREML_MODEL_DIR or cwd. run(raw_data): parse `{"input": [{"f1": v1, ...}]}`, return `{"isAnomaly": int (-1|1), "anomalyScore": float}`. Deps: scikit-learn, numpy.
- **generate_synthetic_opportunities.py (Plan §5.6, TRAINING_SCRIPTS_SPEC §3.6):** `scripts/generate_synthetic_opportunities.py` for risk-scoring / win-probability when real data < 3k/5k. Domain rules: amount log-normal, probability beta, stage categorical, target_risk = f(probability, days_since_activity). Args: --output-path, --n-samples, --tenant-id, --seed, --pct-closed. Output: Parquet to ml_training/synthetic/risk_scoring/ or --output-path. Uses numpy, pandas, pyarrow. No new deps.
- **ModelSelectionService (Plan §5.4, §874):** `selectRiskScoringModel(tenantId, industryId?, features?)` — global vs industry; stub: industry when industryId and `risk_scoring_industry` endpoint; else global. `selectWinProbabilityModel(tenantId)` — stub: `win-probability-model` or `win_probability` when configured. `GET /api/v1/ml/model-selection/risk-scoring?industryId=`, `GET /api/v1/ml/model-selection/win-probability`. OpenAPI and auth.
- **Health (Plan §11.7):** `/health` includes `azureMl: { status, endpoints }` (Azure ML endpoints reachability: ok, degraded, not_configured). Custom /health and /ready replace setupHealthCheck.
- **Observability (Plan §8.5, FIRST_STEPS §1):** `@azure/monitor-opentelemetry` in `src/instrumentation.ts` (init before other imports; env `APPLICATIONINSIGHTS_CONNECTION_STRING`, `APPLICATIONINSIGHTS_DISABLE`). `GET /metrics` (prom-client): `http_requests_total`, `http_request_duration_seconds`, `ml_predictions_total` (label `model`), **`ml_prediction_duration_seconds`** (label `model`, Plan §8.5.2, deployment/monitoring/README). Config: `application_insights` (connection_string, disable), `metrics` (path, require_auth, bearer_token); schema. Optional Bearer on /metrics when `metrics.require_auth`. `ml_predictions_total.inc({ model })` and `mlPredictionDurationSeconds.startTimer()` in risk-scoring, win-probability (predict + explain), forecast, generic /models/:id/predict.
- **AzureMLClient** (BI_SALES_RISK Plan §5.4): REST client for Azure ML Managed Endpoints; `predict(modelId, features)`; config `azure_ml.endpoints` (modelId → scoring URL), `azure_ml.api_key`. Env: `AZURE_ML_WIN_PROBABILITY_URL`, `AZURE_ML_RISK_SCORING_URL`; Plan §8.2 aliases: `AZURE_ML_ENDPOINT_WIN_PROB`, `AZURE_ML_ENDPOINT_RISK_GLOBAL`. Degraded: heuristic when Azure ML unavailable (Plan §5.7).
- **PredictionService.predictWinProbability(tenantId, opportunityId)** (Plan §5.4, §5.7): buildVector('win-probability') → Azure ML `win-probability-model` when configured; on failure use heuristic (vector.probability or 0.5).
- **PredictionService.predictRiskScore** extended: when `body.features` missing → `buildVector('risk-scoring')`; when `azure_ml.endpoints['risk-scoring-model']` set → try Azure ML first, then Cosmos model / heuristic.
- **POST /api/v1/ml/win-probability/predict** (Plan §5.4): body `{ opportunityId }`; returns `{ probability }`; uses Azure ML or heuristic.
- **POST /api/v1/ml/win-probability/explain** (Plan §905, §11.2): body `{ opportunityId }`; returns `{ topDrivers: [{ feature, contribution, direction }] }`. PredictionService.getWinProbabilityExplain: top features by |value| from buildVector('win-probability'); Phase 2: tree importance or SHAP.
- **POST /api/v1/ml/anomaly/predict (Plan §5.5):** body `{ opportunityId }`; returns `{ isAnomaly, anomalyScore }`. PredictionService.predictAnomaly: buildVector('anomaly') → AzureMLClient.predictAnomaly('anomaly', features). Request `{ input: [features] }`; response isAnomaly (-1=anomaly, 1=normal), anomalyScore (higher=more anomalous). Requires azure_ml.endpoints.anomaly. ml_predictions_total, ml_prediction_duration_seconds (model 'anomaly'); ml.prediction.completed from predictAnomaly.
- **POST /api/v1/ml/risk-trajectory/predict (Plan §5.5, §875):** body `{ sequence: number[][] }` (from risk_snapshots [riskScore, 0, 0] per row, pad to 30); returns `{ risk_30, risk_60, risk_90, confidence }`. AzureMLClient.predictLstmTrajectory('risk_trajectory_lstm', sequence); PredictionService.predictLstmTrajectory(sequence). Requires azure_ml.endpoints.risk_trajectory_lstm. 503 when endpoint not configured. ml_predictions_total, ml_prediction_duration_seconds (model 'risk_trajectory_lstm'). OpenAPI /ml/risk-trajectory/predict.
- **Azure ML Job for risk-scoring (Plan §874, §5.6):** `scripts/azml-job-risk-scoring.yaml` — Azure ML v2 command job to run `train_risk_scoring.py`. Inputs: training_data (uri_folder; set path to Data Lake or azureml:dataset:1), model_name, industry_id, deploy_flag (set to `--deploy` to deploy after register). `scripts/conda-risk-scoring-train.yaml` — conda env for the job (pandas, pyarrow, xgboost, azure-ai-ml, azure-identity). `scripts/README.md`: how to submit, synthetic data when real data < 3k via `generate_synthetic_opportunities.py`.
- **Azure ML Job for risk-trajectory-lstm (Plan §875, §5.6):** `scripts/azml-job-lstm-trajectory.yaml` — Azure ML v2 command job to run `train_lstm_trajectory.py`. Inputs: training_data (uri_folder; path to risk_snapshots Parquet or azureml:dataset), model_name, sequence_length (default 30), deploy_flag (set to `--deploy` to deploy). `scripts/conda-lstm-train.yaml` — conda env for the job (pandas, pyarrow, tensorflow, azure-ai-ml, azure-identity). `scripts/README.md`: input schema (opportunityId, snapshotDate, risk_score, activity_count_30d, days_since_last_activity, target_risk_30/60/90 or target_risk); SEQUENCE_LENGTH for scoring.
- **Azure ML Job for win-probability (Plan §876, §5.6):** `scripts/azml-job-win-probability.yaml` — Azure ML v2 command job to run `train_win_probability.py`. Inputs: training_data (uri_folder; path to Parquet or azureml:dataset), model_name (default win-probability-model), deploy_flag (set to `--deploy` to deploy). `scripts/conda-win-probability-train.yaml` — conda env for the job (pandas, pyarrow, scikit-learn, xgboost, azure-ai-ml, azure-identity). Input schema: amount, probability, days_to_close, stage_encoded, industry_encoded, days_since_last_activity, activity_count_30d, stakeholder_count, target_win; is_closed; source: /ml_training/win_probability/, risk_evaluations+outcomes, or generate_synthetic_opportunities --pct-closed.
- **Azure ML Job for revenue-forecasting (Plan §877, §5.6):** `scripts/azml-job-prophet.yaml` — Azure ML v2 command job to run `train_prophet_forecast.py`. Inputs: training_data (uri_folder; path to Parquet or azureml:dataset), model_name (default revenue-forecasting-model), deploy_flag (set to `--deploy` to deploy). `scripts/conda-prophet-train.yaml` — conda env for the job (pandas, pyarrow, prophet, joblib, azure-ai-ml, azure-identity). Input: (date, revenue) or (ds, y) or (date, pipeline_value) or (date, target_revenue); source: /ml_training/revenue_forecasting/, historical closed-won or pipeline by date.
- **Azure ML Job for anomaly (Plan Phase 2, TRAINING_SCRIPTS_SPEC §3.4):** `scripts/azml-job-anomaly.yaml` — Azure ML v2 command job to run `train_anomaly_isolation_forest.py`. Inputs: training_data (uri_folder), model_name (default anomaly-detection-isolation-forest), param_contamination (default 0.1), param_n_estimators (default 100), deploy_flag (set to `--deploy` to deploy). `scripts/conda-anomaly-train.yaml` — conda env for the job (pandas, pyarrow, scikit-learn, joblib, azure-ai-ml, azure-identity). Input: feature columns only; optional is_anomaly; source: /ml_training/anomaly/ or /ml_inference_logs/. `scripts/README.md`.
- **FeatureService.buildVectorForOpportunity(tenantId, opportunityId, purpose)** (BI_SALES_RISK_FEATURE_PIPELINE_SPEC, FIRST_STEPS §6): builds `Record<string, number>` from shard-manager (opportunity, account, /related for c_email, c_call, c_meeting, c_contact) and risk-analytics (risk-snapshots). Config: `services.shard_manager.url`, `services.risk_analytics.url`; optional `feature_pipeline.stage_labels`, `feature_pipeline.industry_labels`.
- **FeatureService:** fallback to risk-analytics `GET /api/v1/risk/opportunities/:id/latest-evaluation` when risk-snapshots is empty (FEATURE_PIPELINE_SPEC §2.2).
- **POST /api/v1/ml/features/build** (FIRST_STEPS §6): body `{ opportunityId, purpose }` (purpose: risk-scoring | win-probability | lstm | anomaly | forecasting); returns `{ features: Record<string, number> }`; 404 when opportunity not found.
- **README:** Document `POST /api/v1/ml/features/build`, `services.shard_manager.url`, `services.risk_analytics.url`, and `feature_pipeline.stage_labels` / `industry_labels` (FEATURE_PIPELINE_SPEC §6, FIRST_STEPS §6).
- **ml.prediction.completed (Plan §7.1, §3.5):** ml-service publishes `ml.prediction.completed` from `predictWinProbability`, `predictRiskScore`, and `predictForecast` with `{ modelId, opportunityId?, inferenceMs }` for logging/audit (MLAuditConsumer) and Usage Tracking (analytics-service). Event publisher init/close in server startup and graceful shutdown.
- **Config (Plan §895, §8.2):** `feature_flags` (use_win_probability_ml, use_risk_scoring_ml, use_revenue_forecasting_ml; env USE_*). `azure_ml.endpoints` Plan §8.2: risk_scoring_global, risk_scoring_industry, risk_trajectory_lstm, win_probability, revenue_forecasting, clustering, propagation, anomaly, mitigation_ranking; backward compat: win-probability-model, risk-scoring-model. Env: AZURE_ML_ENDPOINT_RISK_GLOBAL, AZURE_ML_ENDPOINT_WIN_PROB, etc.
- **Config (Plan §867, §8.2):** `azure_ml.workspace_name`, `azure_ml.resource_group`, `azure_ml.subscription_id` for Azure ML Workspace (SDK, batch, deployment). Env: `AZURE_ML_WORKSPACE_NAME`, `AZURE_ML_RESOURCE_GROUP`, `AZURE_ML_SUBSCRIPTION_ID`; default `resource_group`: `castiel-ml-prod-rg` (Plan §5.1).
- **Model card (Plan §11.9, §946):** `MLModelService.getModelCard(modelId, tenantId)` returns `{ modelId, name, type, version, purpose, input, output, limitations }`. Purpose from description or "Model for {type}"; input = features; output by ModelType; limitations from `ml_models.limitations` or `[]`. `GET /api/v1/ml/models/:id/card`. Optional `limitations` on `MLModel` and `UpdateMLModelInput` (writable via PUT /ml/models/:id). Segment fairness in model-monitoring: §946 (alert if delta > threshold) deferred to model-monitoring job.
- **Model monitoring (Plan §940, §9.3):** `ModelMonitoringService.runForTenants(tenantIds)`. Stub returns `{ driftChecked: 0, performanceChecked: 0 }`. Full: log feature vector at inference (Data Lake or ml_inference_logs); drift (PSI), performance (Brier, MAE); publish `ml.model.drift.detected` / `ml.model.performance.degraded`; runbook. `POST /api/v1/ml/model-monitoring/run` body `{ tenantIds?: string[] }` — internal, called by risk-analytics BatchJobWorker. No auth (internal); service-to-service JWT TBD.

## [1.2.0] - 2026-01-23

### Fixed
- **PredictionService**: `error: any` → `error: unknown` in predict, recordOutcome, getById, list; `error.code` via `(error as { code?: number }).code`; throw/console.warn messages use type guards.
- **FeatureService**: `error: any` → `error: unknown` in getAdaptiveFeatureWeights, create, getById, update, list; `error.code` via type assertion; throw messages use type guards.

## [1.1.0] - 2026-01-23

### Added
- `POST /api/v1/ml/risk-scoring/predict` (MISSING_FEATURES 4.2): risk-scoring endpoint used by risk-analytics; uses deployed model when available, falls back to feature-based heuristic when model is missing or not deployed
- `PredictionService.predictRiskScore()` for risk-scoring flow
- `POST /api/v1/ml/forecast/predict` (MISSING_FEATURES 5.1): revenue forecast with P10/P50/P90 (uncertainty), best/base/worst scenarios; uses deployed model when available, else feature-based heuristic; consumed by forecasting service
- `PredictionService.predictForecast()` for forecast flow

## [1.0.0] - 2025-01-22

### Added
- Initial module extraction from monolithic API
- Feature store service
- Model management service
- Training service
- Evaluation service
- Calibration service
- Synthetic data service
- Risk scoring predictions
- Revenue forecasting
- ML-based recommendations
- Event publishing
- Cosmos DB NoSQL integration

